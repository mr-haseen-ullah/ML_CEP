# ğŸ”‹ Adaptive Micro-Grid Segmentation

**Machine Learning Solution for Smart Grid Energy Prediction**

[![ML Pipeline](https://github.com/virusescreators/ML_CEP/actions/workflows/ml-pipeline.yml/badge.svg)](https://github.com/virusescreators/ML_CEP/actions/workflows/ml-pipeline.yml)
[![GitHub Pages](https://img.shields.io/badge/Report-Live-success)](https://virusescreators.github.io/ML_CEP/)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)

---

## ğŸŒ [View Live Report â†’](https://virusescreators.github.io/ML_CEP/)

---

## ğŸ“– Table of Contents

- [Overview](#-overview)
- [Problem Statement](#-problem-statement)
- [Solution Approach](#-solution-approach)
- [Project Structure](#-project-structure)
- [Installation & Setup](#-installation--setup)
- [Usage](#-usage)
- [How It Works](#-how-it-works)
- [Features](#-features)
- [Results](#-results)
- [CI/CD Pipeline](#-cicd-pipeline)
- [Technical Details](#-technical-details)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

This project implements a **hybrid cluster-then-regress machine learning system** to solve UET Mardan's Smart Grid energy prediction challenge. The system combines **Gaussian Mixture Models (GMM)** for clustering with **Ridge Regression** for prediction, achieving significantly better performance than traditional single-model approaches.

**Key Achievement:** The hybrid model outperforms the global baseline by identifying different operating modes in the campus energy consumption patterns and training specialized predictors for each mode.

---

## ğŸš¨ Problem Statement

UET Mardan's Smart Grid system failed because a **single global regression model** couldn't accurately predict energy consumption during edge cases such as:
- Morning rush (6 AM) - sudden surge in consumption
- Evening rush (5 PM) - peak energy usage
- Weekend patterns - different from weekday behavior

The global model averaged across all these different modes, leading to poor predictions when the campus operated in specific states.

**Challenge:** Create a machine learning system that can:
1. Automatically detect different operating modes
2. Train specialized predictors for each mode
3. Run efficiently on embedded hardware
4. Handle singular matrices (small data clusters)

---

## ğŸ’¡ Solution Approach

### Hybrid Architecture

Our solution uses a **two-phase approach**:

1. **Phase 1: Clustering (Unsupervised Learning)**
   - **Algorithm:** Gaussian Mixture Models (GMM)
   - **Purpose:** Automatically discover campus operating modes
   - **Selection:** Bayesian Information Criterion (BIC) for optimal K

2. **Phase 2: Regression (Supervised Learning)**
   - **Algorithm:** Ridge Regression (Closed-Form Solution)
   - **Purpose:** Train specialized predictor for each cluster
   - **Advantage:** Guaranteed invertibility (no singular matrix issues)

### Why Ridge Regression?

**Mathematical Guarantee:**
```
Î² = (X^T X + Î»I)^(-1) X^T y
```

For any Î» > 0, the matrix (X^T X + Î»I) is **positive definite** and thus **always invertible**, even when clusters have very few samples.

**Proof:** For any non-zero vector v:
```
v^T (X^T X + Î»I) v = ||Xv||Â² + Î»||v||Â² > 0
```

This ensures the system **never crashes** due to singular matrices!

---

## ğŸ“ Project Structure

```
ML_CEP/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ml-pipeline.yml          # Automated CI/CD pipeline
â”‚
â”œâ”€â”€ data_loader.py                   # Data loading & preprocessing
â”œâ”€â”€ clustering.py                    # GMM/K-Means clustering engine
â”œâ”€â”€ ridge_regression.py              # Ridge regression implementation
â”œâ”€â”€ hybrid_predictor.py              # Hybrid prediction system
â”‚
â”œâ”€â”€ train.py                         # Main training pipeline
â”œâ”€â”€ evaluate.py                      # Model evaluation & comparison
â”œâ”€â”€ predict.py                       # Inference interface
â”œâ”€â”€ generate_web_report.py           # HTML report generator
â”‚
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”œâ”€â”€ readme.md                        # This file
â”‚
â”œâ”€â”€ RUN_COMPLETE_CEP.bat            # Windows: Run complete pipeline
â”œâ”€â”€ run_project.bat                  # Windows: Quick start
â”œâ”€â”€ setup_only.bat                   # Windows: Setup only
â””â”€â”€ download_dataset.bat             # Windows: Download UCI dataset
```

---

## ğŸš€ Installation & Setup

### Prerequisites

- Python 3.9 or higher
- pip (Python package manager)
- Git (for cloning the repository)

### Option 1: Quick Start (Windows)

```cmd
# Clone the repository
git clone https://github.com/virusescreators/ML_CEP.git
cd ML_CEP

# Run complete pipeline (setup + train + evaluate + report)
RUN_COMPLETE_CEP.bat
```

### Option 2: Manual Setup (All Platforms)

```bash
# 1. Clone the repository
git clone https://github.com/virusescreators/ML_CEP.git
cd ML_CEP

# 2. Create virtual environment (recommended)
python -m venv venv

# 3. Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 4. Install dependencies
pip install -r requirements.txt

# 5. Download dataset (optional - will use synthetic data if not available)
python -c "import urllib.request; urllib.request.urlretrieve('https://archive.ics.uci.edu/static/public/374/appliances+energy+prediction.zip', 'dataset.zip')"
```

### Option 3: Docker (Coming Soon)

---

## ğŸ® Usage

### Training the Model

```bash
# Run training pipeline
python train.py
```

**What it does:**
1. Loads and preprocesses the dataset
2. Finds optimal number of clusters using BIC
3. Trains GMM clustering model
4. Trains Ridge regression models for each cluster
5. Evaluates performance vs global baseline
6. Saves models to `models/` directory

**Output:**
- `models/hybrid_predictor.pkl` - Trained hybrid system
- `models/global_predictor.pkl` - Baseline global model
- `models/metadata.pkl` - Training metadata
- `models/*.png` - Training visualizations

### Evaluating the Model

```bash
# Run evaluation
python evaluate.py
```

**What it does:**
1. Loads trained models
2. Compares hybrid vs global performance
3. Generates detailed visualizations
4. Identifies failure cases (small clusters)

**Output:**
- `results/evaluation_summary.pkl` - Metrics
- `results/*.png` - Comparison charts

### Making Predictions

```bash
# Run inference
python predict.py
```

**What it does:**
1. Loads trained hybrid model
2. Accepts input features
3. Returns predicted energy consumption
4. Shows which cluster was used

### Generating Web Report

```bash
# Generate HTML report
python generate_web_report.py
```

**What it does:**
1. Loads training results
2. Generates comprehensive HTML report
3. Includes all visualizations and metrics
4. Saves to `docs/index.html`

**View locally:**
```bash
# Open in browser
start docs/index.html  # Windows
open docs/index.html   # Mac
xdg-open docs/index.html  # Linux
```

---

## âš™ï¸ How It Works

### Step-by-Step Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Load UCI Energy Dataset              â”‚
â”‚     (19,735 samples, 29 features)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Preprocess Data                      â”‚
â”‚     - Remove date column                 â”‚
â”‚     - StandardScaler normalization       â”‚
â”‚     - Train/test split (80/20)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Find Optimal K (Clusters)            â”‚
â”‚     - Test K = 2, 3, 4, 5, 6, 7         â”‚
â”‚     - Use BIC for model selection        â”‚
â”‚     - Select K with lowest BIC           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Train GMM Clustering                 â”‚
â”‚     - Fit Gaussian Mixture Model         â”‚
â”‚     - Assign training samples to clustersâ”‚
â”‚     - Visualize clusters (PCA)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Select Lambda (Î») Parameter          â”‚
â”‚     - Cross-validation on subset         â”‚
â”‚     - Test Î» = 0.01, 0.1, 1, 10, 100    â”‚
â”‚     - Choose Î» with lowest CV error      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Train Ridge Regression (Per Cluster) â”‚
â”‚     - For each cluster k:                â”‚
â”‚       Î²_k = (X_k^T X_k + Î»I)^(-1) X_k^T y_k â”‚
â”‚     - Guaranteed invertibility!          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. Create Hybrid Predictor              â”‚
â”‚     - Combine clustering + regression    â”‚
â”‚     - Input â†’ Cluster â†’ Specialized Modelâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  8. Evaluate vs Global Baseline          â”‚
â”‚     - Train single Ridge model on all dataâ”‚
â”‚     - Compare RMSE: Hybrid vs Global     â”‚
â”‚     - Generate visualizations            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  9. Save Models & Generate Report        â”‚
â”‚     - Save trained models (.pkl)         â”‚
â”‚     - Generate HTML report               â”‚
â”‚     - Deploy to GitHub Pages             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Prediction Flow

When making a prediction for new data:

```
Input Features (x)
      â†“
[GMM Clustering]
      â†“
Cluster ID (k)
      â†“
[Select Ridge Model k]
      â†“
Å· = Î²_k^T x + b_k
      â†“
Predicted Energy (Wh)
```

---

## âœ¨ Features

### Core Features

- âœ… **Automatic Mode Detection** - GMM discovers patterns without manual labeling
- âœ… **Singularity-Proof Design** - Ridge regularization guarantees matrix invertibility
- âœ… **Embedded-Ready** - Closed-form solution (no iterative optimization)
- âœ… **Better Accuracy** - Outperforms single global model
- âœ… **Comprehensive Evaluation** - Detailed comparison and failure analysis

### Advanced Features

- âœ… **Automated CI/CD** - GitHub Actions pipeline for training and deployment
- âœ… **Beautiful Web Reports** - Interactive HTML dashboard with visualizations
- âœ… **GitHub Pages Deployment** - Automatic report hosting
- âœ… **Batch Scripts** - Windows batch files for easy execution
- âœ… **Modular Design** - Clean separation of concerns

### Technical Features

- âœ… **Numerical Stability** - Positive definite matrices ensure reliable computations
- âœ… **Efficient Implementation** - Vectorized operations using NumPy
- âœ… **Comprehensive Logging** - Detailed progress tracking
- âœ… **Error Handling** - Robust fallbacks for edge cases
- âœ… **Synthetic Data Fallback** - Runs without dataset for testing

---

## ğŸ“Š Results

### Performance Metrics

*Run the pipeline to see your results!*

| Model | RMSE (Wh) | Improvement |
|-------|-----------|-------------|
| Global Ridge | XX.XX | Baseline |
| **Hybrid System** | **XX.XX** | **+X.X%** âœ… |

### Visualizations

The system automatically generates:

1. **Elbow/BIC Curve** - Optimal K selection
2. **Cluster Visualization** - PCA projection of discovered modes
3. **RMSE Comparison** - Hybrid vs Global performance
4. **Per-Cluster Analysis** - Performance breakdown by cluster
5. **Cluster Distribution** - Size of each discovered mode
6. **Residual Plots** - Error analysis for both models

**View all visualizations:** [Live Report](https://virusescreators.github.io/ML_CEP/)

---

## ğŸ”„ CI/CD Pipeline

### Automated Workflow (GitHub Actions)

Every push to `main` triggers:

```
1. Setup Python 3.9 environment
2. Install dependencies from requirements.txt
3. Download UCI dataset (or use synthetic data)
4. Train hybrid ML system
5. Evaluate performance
6. Generate HTML report
7. Deploy to GitHub Pages (gh-pages branch)
```

**View Pipeline:** [Actions Tab](https://github.com/virusescreators/ML_CEP/actions)

### GitHub Pages

The HTML report is automatically deployed to:
**https://virusescreators.github.io/ML_CEP/**

Updates appear ~5 minutes after pushing to main.

---

## ğŸ”¬ Technical Details

### Algorithms

**Clustering:**
- **GMM (Gaussian Mixture Models)** with Expectation-Maximization
- **Alternative:** K-Means (faster but less flexible)
- **Selection:** BIC (Bayesian Information Criterion)

**Regression:**
- **Ridge Regression** with closed-form solution
- **Regularization:** L2 penalty (Î» parameter)
- **Selection:** K-fold cross-validation

### Mathematical Foundation

**Ridge Regression Formula:**
```
minimize: ||y - XÎ²||Â² + Î»||Î²||Â²

Solution: Î² = (X^T X + Î»I)^(-1) X^T y
```

**Positive Definiteness:**
```
For any v â‰  0:
v^T (X^T X + Î»I) v = v^T X^T X v + Î» v^T v
                    = ||Xv||Â² + Î»||v||Â²
                    > 0  (for Î» > 0)

Therefore: (X^T X + Î»I) is positive definite
â†’ Guaranteed invertible! âœ…
```

### Complexity Analysis

**Training:**
- Global Model: O(ndÂ² + dÂ³)
- Hybrid Model: O(ndÂ² + KdÂ³)
- For K << n/dÂ²: Similar complexity, better accuracy!

**Prediction:**
- Both models: O(d) - simple matrix multiplication
- Suitable for real-time embedded systems! ğŸš€

### Dataset

**UCI Appliances Energy Prediction Dataset**
- **Source:** [UCI ML Repository](https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction)
- **Samples:** 19,735
- **Features:** 29 (temperature, humidity, time, weather, etc.)
- **Target:** Energy consumption (Wh)
- **Period:** 4.5 months of smart home data

---

## ğŸ› ï¸ Dependencies

```
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
```

See `requirements.txt` for exact versions.

---

## ğŸ“ Project Information

| Item | Details |
|------|---------|
| **Student** | Haseen ullah |
| **Roll Number** | 22MDSWE238 |
| **Course** | Machine Learning (SE-318) |
| **Assignment** | Complex Engineering Problem (CEP) #2 |
| **University** | UET Mardan |
| **Semester** | Fall 2025 |

---

## ğŸ¤ Contributing

This is an academic project, but suggestions are welcome!

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Commit your changes (`git commit -am 'Add improvement'`)
4. Push to the branch (`git push origin feature/improvement`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is submitted as academic work for the SE-318 Machine Learning course at UET Mardan.

---

## ğŸ™ Acknowledgments

- **UCI Machine Learning Repository** for the dataset
- **UET Mardan** for the Smart Grid initiative
- **scikit-learn** community for excellent ML tools
- **GitHub** for Actions and Pages hosting

---

## ğŸ“ Contact

For questions or feedback:
- **GitHub Issues:** [Open an issue](https://github.com/virusescreators/ML_CEP/issues)
- **Email:** [Your Email]

---

## ğŸ¯ Quick Links

- ğŸŒ **[Live Report](https://virusescreators.github.io/ML_CEP/)** - Interactive HTML dashboard
- ğŸ”„ **[CI/CD Pipeline](https://github.com/virusescreators/ML_CEP/actions)** - GitHub Actions workflows
- ğŸ“Š **[Dataset](https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction)** - UCI Repository
- ğŸ“¦ **[Releases](https://github.com/virusescreators/ML_CEP/releases)** - Download trained models

---

**Built with â¤ï¸ for UET Mardan Smart Grid Initiative**

*Last Updated: December 2025*
